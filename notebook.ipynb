{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJGrwq-I9Uxy"
      },
      "source": [
        "### 0. Use Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H7-7-lD2Iuj",
        "outputId": "fa787dc3-e5f8-4dac-9e6e-921ea6df2cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HolaiWOX3jPL"
      },
      "outputs": [],
      "source": [
        "!pip install -r drive/MyDrive/CV_Transformer/requirements.txt\n",
        "!pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHtEab4S2HzU"
      },
      "source": [
        "### 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0-sczZSR2HzZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from drive.MyDrive.CV_Transformer.src.ViT import ViT_classifier\n",
        "from drive.MyDrive.CV_Transformer.src.BuildingBlocks import Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8eQLm0ZJ2Hzb"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04POw8yy2Hzc"
      },
      "source": [
        "### 2. Data loading and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fAq7nxa2Hzc",
        "outputId": "fddd418d-c9d0-4340-a2e3-921e86744a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoupBLKGjCjP",
        "outputId": "16404e5a-96ad-479a-9a7a-8db6b6c4b8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "(x_train, ys_train), (x_test, ys_test) = keras.datasets.cifar100.load_data(label_mode='coarse')\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tYHENVS2Hzh"
      },
      "source": [
        "### 3. Train ViT - classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYaWf6-32Hzd"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tE-hWZew2Hze"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"learning_rate\" : 0.001,\n",
        "    \"weight_decay\" : 0.0001,\n",
        "    \"MLP_dropout_rate\" : 0.5,\n",
        "    \"TB_dropout_rate\" : 0.6,\n",
        "    \"batch_size\" : 256,\n",
        "    \"num_epochs\" : 100,\n",
        "    \"input_shape\" : (32, 32, 3),\n",
        "    \"num_classes\" : 100,\n",
        "    \"image_size\" : 72,  # We'll resize input images to this size\n",
        "    \"patch_size\" : 6,  # Size of the patches to be extract from the input images\n",
        "    \"projection_dim\" : 64,\n",
        "    \"num_heads\" : 4,\n",
        "    \"transformer_units\" : [128, 64], # Size of the transformer layers\n",
        "    \"transformer_layers\" : 8,\n",
        "    \"mlp_head_units\" : [2048, 1024]  # Size of the dense layers of the final classifier\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX2zVYngjoYc"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaC4bSuu2Hzi",
        "outputId": "8fa753fe-087c-4b44-a855-d46619684bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 90s 379ms/step - loss: 4.4470 - accuracy: 0.0495 - top-5-accuracy: 0.1694 - val_loss: 3.8262 - val_accuracy: 0.1164 - val_top-5-accuracy: 0.3194\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 3.9097 - accuracy: 0.1016 - top-5-accuracy: 0.3019 - val_loss: 3.5314 - val_accuracy: 0.1646 - val_top-5-accuracy: 0.4238\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 65s 369ms/step - loss: 3.6598 - accuracy: 0.1354 - top-5-accuracy: 0.3765 - val_loss: 3.2881 - val_accuracy: 0.2102 - val_top-5-accuracy: 0.4922\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 3.4913 - accuracy: 0.1638 - top-5-accuracy: 0.4272 - val_loss: 3.1532 - val_accuracy: 0.2414 - val_top-5-accuracy: 0.5266\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 3.3440 - accuracy: 0.1915 - top-5-accuracy: 0.4690 - val_loss: 3.0599 - val_accuracy: 0.2560 - val_top-5-accuracy: 0.5456\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 3.2120 - accuracy: 0.2167 - top-5-accuracy: 0.5038 - val_loss: 2.9608 - val_accuracy: 0.2720 - val_top-5-accuracy: 0.5680\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 3.0876 - accuracy: 0.2392 - top-5-accuracy: 0.5320 - val_loss: 2.8105 - val_accuracy: 0.3010 - val_top-5-accuracy: 0.6020\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 65s 369ms/step - loss: 2.9557 - accuracy: 0.2642 - top-5-accuracy: 0.5644 - val_loss: 2.7350 - val_accuracy: 0.3124 - val_top-5-accuracy: 0.6162\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 2.8499 - accuracy: 0.2883 - top-5-accuracy: 0.5912 - val_loss: 2.6320 - val_accuracy: 0.3372 - val_top-5-accuracy: 0.6376\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 65s 369ms/step - loss: 2.7500 - accuracy: 0.3084 - top-5-accuracy: 0.6142 - val_loss: 2.5363 - val_accuracy: 0.3530 - val_top-5-accuracy: 0.6628\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 66s 374ms/step - loss: 2.6634 - accuracy: 0.3244 - top-5-accuracy: 0.6360 - val_loss: 2.4560 - val_accuracy: 0.3778 - val_top-5-accuracy: 0.6778\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 2.5829 - accuracy: 0.3407 - top-5-accuracy: 0.6513 - val_loss: 2.4352 - val_accuracy: 0.3786 - val_top-5-accuracy: 0.6804\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 2.5157 - accuracy: 0.3519 - top-5-accuracy: 0.6679 - val_loss: 2.3489 - val_accuracy: 0.4018 - val_top-5-accuracy: 0.7022\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 2.4411 - accuracy: 0.3670 - top-5-accuracy: 0.6847 - val_loss: 2.3263 - val_accuracy: 0.4022 - val_top-5-accuracy: 0.7030\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 2.3657 - accuracy: 0.3840 - top-5-accuracy: 0.7002 - val_loss: 2.2434 - val_accuracy: 0.4228 - val_top-5-accuracy: 0.7204\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 2.2974 - accuracy: 0.3967 - top-5-accuracy: 0.7141 - val_loss: 2.2332 - val_accuracy: 0.4258 - val_top-5-accuracy: 0.7262\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 2.2443 - accuracy: 0.4087 - top-5-accuracy: 0.7256 - val_loss: 2.2035 - val_accuracy: 0.4254 - val_top-5-accuracy: 0.7276\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 2.1856 - accuracy: 0.4184 - top-5-accuracy: 0.7385 - val_loss: 2.1653 - val_accuracy: 0.4346 - val_top-5-accuracy: 0.7384\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 2.1363 - accuracy: 0.4319 - top-5-accuracy: 0.7475 - val_loss: 2.0920 - val_accuracy: 0.4514 - val_top-5-accuracy: 0.7440\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 2.0605 - accuracy: 0.4482 - top-5-accuracy: 0.7617 - val_loss: 2.0714 - val_accuracy: 0.4590 - val_top-5-accuracy: 0.7522\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 2.0125 - accuracy: 0.4610 - top-5-accuracy: 0.7715 - val_loss: 2.0674 - val_accuracy: 0.4580 - val_top-5-accuracy: 0.7538\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.9678 - accuracy: 0.4705 - top-5-accuracy: 0.7824 - val_loss: 2.0584 - val_accuracy: 0.4602 - val_top-5-accuracy: 0.7526\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.9202 - accuracy: 0.4822 - top-5-accuracy: 0.7893 - val_loss: 2.0081 - val_accuracy: 0.4688 - val_top-5-accuracy: 0.7650\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.8735 - accuracy: 0.4923 - top-5-accuracy: 0.7970 - val_loss: 2.0094 - val_accuracy: 0.4736 - val_top-5-accuracy: 0.7598\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.8224 - accuracy: 0.5044 - top-5-accuracy: 0.8080 - val_loss: 1.9732 - val_accuracy: 0.4810 - val_top-5-accuracy: 0.7704\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 66s 372ms/step - loss: 1.7787 - accuracy: 0.5108 - top-5-accuracy: 0.8166 - val_loss: 1.9494 - val_accuracy: 0.4896 - val_top-5-accuracy: 0.7818\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.7400 - accuracy: 0.5198 - top-5-accuracy: 0.8220 - val_loss: 1.9400 - val_accuracy: 0.4896 - val_top-5-accuracy: 0.7834\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.7111 - accuracy: 0.5310 - top-5-accuracy: 0.8281 - val_loss: 1.8949 - val_accuracy: 0.4984 - val_top-5-accuracy: 0.7854\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.6831 - accuracy: 0.5341 - top-5-accuracy: 0.8350 - val_loss: 1.8992 - val_accuracy: 0.4902 - val_top-5-accuracy: 0.7878\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 1.6343 - accuracy: 0.5460 - top-5-accuracy: 0.8410 - val_loss: 1.9181 - val_accuracy: 0.4900 - val_top-5-accuracy: 0.7888\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.6012 - accuracy: 0.5532 - top-5-accuracy: 0.8461 - val_loss: 1.8813 - val_accuracy: 0.5064 - val_top-5-accuracy: 0.7822\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.5656 - accuracy: 0.5616 - top-5-accuracy: 0.8535 - val_loss: 1.8750 - val_accuracy: 0.5096 - val_top-5-accuracy: 0.7876\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.5301 - accuracy: 0.5694 - top-5-accuracy: 0.8602 - val_loss: 1.8740 - val_accuracy: 0.5134 - val_top-5-accuracy: 0.7928\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.5119 - accuracy: 0.5752 - top-5-accuracy: 0.8636 - val_loss: 1.8510 - val_accuracy: 0.5186 - val_top-5-accuracy: 0.7974\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.4791 - accuracy: 0.5795 - top-5-accuracy: 0.8673 - val_loss: 1.8657 - val_accuracy: 0.5154 - val_top-5-accuracy: 0.7944\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 1.4571 - accuracy: 0.5914 - top-5-accuracy: 0.8708 - val_loss: 1.8429 - val_accuracy: 0.5172 - val_top-5-accuracy: 0.7970\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.4175 - accuracy: 0.5989 - top-5-accuracy: 0.8770 - val_loss: 1.8475 - val_accuracy: 0.5124 - val_top-5-accuracy: 0.8016\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.3980 - accuracy: 0.6043 - top-5-accuracy: 0.8786 - val_loss: 1.8434 - val_accuracy: 0.5250 - val_top-5-accuracy: 0.8032\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.3700 - accuracy: 0.6116 - top-5-accuracy: 0.8839 - val_loss: 1.8468 - val_accuracy: 0.5240 - val_top-5-accuracy: 0.7996\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 1.3507 - accuracy: 0.6152 - top-5-accuracy: 0.8875 - val_loss: 1.8552 - val_accuracy: 0.5212 - val_top-5-accuracy: 0.7982\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.3316 - accuracy: 0.6200 - top-5-accuracy: 0.8902 - val_loss: 1.8760 - val_accuracy: 0.5240 - val_top-5-accuracy: 0.7958\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.3084 - accuracy: 0.6258 - top-5-accuracy: 0.8956 - val_loss: 1.8713 - val_accuracy: 0.5174 - val_top-5-accuracy: 0.8050\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.2965 - accuracy: 0.6288 - top-5-accuracy: 0.8963 - val_loss: 1.8695 - val_accuracy: 0.5256 - val_top-5-accuracy: 0.8060\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.2581 - accuracy: 0.6367 - top-5-accuracy: 0.9009 - val_loss: 1.8765 - val_accuracy: 0.5252 - val_top-5-accuracy: 0.7996\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.2533 - accuracy: 0.6397 - top-5-accuracy: 0.9009 - val_loss: 1.8482 - val_accuracy: 0.5268 - val_top-5-accuracy: 0.8034\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 1.2265 - accuracy: 0.6446 - top-5-accuracy: 0.9069 - val_loss: 1.8624 - val_accuracy: 0.5262 - val_top-5-accuracy: 0.8036\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.2106 - accuracy: 0.6493 - top-5-accuracy: 0.9085 - val_loss: 1.8527 - val_accuracy: 0.5260 - val_top-5-accuracy: 0.8028\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 66s 375ms/step - loss: 1.1835 - accuracy: 0.6570 - top-5-accuracy: 0.9119 - val_loss: 1.8648 - val_accuracy: 0.5280 - val_top-5-accuracy: 0.8008\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.1787 - accuracy: 0.6576 - top-5-accuracy: 0.9143 - val_loss: 1.8457 - val_accuracy: 0.5310 - val_top-5-accuracy: 0.8080\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.1664 - accuracy: 0.6596 - top-5-accuracy: 0.9155 - val_loss: 1.8447 - val_accuracy: 0.5316 - val_top-5-accuracy: 0.8084\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.1347 - accuracy: 0.6670 - top-5-accuracy: 0.9209 - val_loss: 1.8804 - val_accuracy: 0.5248 - val_top-5-accuracy: 0.8012\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.1272 - accuracy: 0.6715 - top-5-accuracy: 0.9196 - val_loss: 1.8750 - val_accuracy: 0.5306 - val_top-5-accuracy: 0.8034\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.1161 - accuracy: 0.6741 - top-5-accuracy: 0.9210 - val_loss: 1.8337 - val_accuracy: 0.5378 - val_top-5-accuracy: 0.8084\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 1.0925 - accuracy: 0.6794 - top-5-accuracy: 0.9245 - val_loss: 1.8556 - val_accuracy: 0.5304 - val_top-5-accuracy: 0.8048\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.0914 - accuracy: 0.6803 - top-5-accuracy: 0.9238 - val_loss: 1.8660 - val_accuracy: 0.5340 - val_top-5-accuracy: 0.8044\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.0753 - accuracy: 0.6845 - top-5-accuracy: 0.9265 - val_loss: 1.8734 - val_accuracy: 0.5320 - val_top-5-accuracy: 0.8120\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 1.0583 - accuracy: 0.6899 - top-5-accuracy: 0.9289 - val_loss: 1.8720 - val_accuracy: 0.5324 - val_top-5-accuracy: 0.8080\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.0540 - accuracy: 0.6889 - top-5-accuracy: 0.9301 - val_loss: 1.8998 - val_accuracy: 0.5354 - val_top-5-accuracy: 0.8080\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.0286 - accuracy: 0.6975 - top-5-accuracy: 0.9322 - val_loss: 1.8669 - val_accuracy: 0.5312 - val_top-5-accuracy: 0.8100\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.0261 - accuracy: 0.6982 - top-5-accuracy: 0.9342 - val_loss: 1.8672 - val_accuracy: 0.5328 - val_top-5-accuracy: 0.8108\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.0227 - accuracy: 0.6991 - top-5-accuracy: 0.9340 - val_loss: 1.8701 - val_accuracy: 0.5364 - val_top-5-accuracy: 0.8016\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.0047 - accuracy: 0.7020 - top-5-accuracy: 0.9359 - val_loss: 1.8794 - val_accuracy: 0.5352 - val_top-5-accuracy: 0.8058\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 0.9940 - accuracy: 0.7038 - top-5-accuracy: 0.9370 - val_loss: 1.8845 - val_accuracy: 0.5346 - val_top-5-accuracy: 0.8072\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.9887 - accuracy: 0.7073 - top-5-accuracy: 0.9398 - val_loss: 1.9106 - val_accuracy: 0.5320 - val_top-5-accuracy: 0.7968\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.9680 - accuracy: 0.7124 - top-5-accuracy: 0.9405 - val_loss: 1.8809 - val_accuracy: 0.5378 - val_top-5-accuracy: 0.8094\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.9636 - accuracy: 0.7139 - top-5-accuracy: 0.9411 - val_loss: 1.8790 - val_accuracy: 0.5310 - val_top-5-accuracy: 0.8062\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 65s 369ms/step - loss: 0.9542 - accuracy: 0.7165 - top-5-accuracy: 0.9424 - val_loss: 1.8823 - val_accuracy: 0.5406 - val_top-5-accuracy: 0.8068\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.9510 - accuracy: 0.7204 - top-5-accuracy: 0.9430 - val_loss: 1.9283 - val_accuracy: 0.5282 - val_top-5-accuracy: 0.8052\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.9443 - accuracy: 0.7199 - top-5-accuracy: 0.9427 - val_loss: 1.8968 - val_accuracy: 0.5356 - val_top-5-accuracy: 0.8112\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.9324 - accuracy: 0.7230 - top-5-accuracy: 0.9457 - val_loss: 1.8695 - val_accuracy: 0.5370 - val_top-5-accuracy: 0.8114\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 0.9210 - accuracy: 0.7260 - top-5-accuracy: 0.9463 - val_loss: 1.8850 - val_accuracy: 0.5382 - val_top-5-accuracy: 0.8050\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 0.9169 - accuracy: 0.7271 - top-5-accuracy: 0.9467 - val_loss: 1.8958 - val_accuracy: 0.5454 - val_top-5-accuracy: 0.8092\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.9004 - accuracy: 0.7281 - top-5-accuracy: 0.9496 - val_loss: 1.8958 - val_accuracy: 0.5438 - val_top-5-accuracy: 0.8096\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.9058 - accuracy: 0.7292 - top-5-accuracy: 0.9471 - val_loss: 1.9124 - val_accuracy: 0.5340 - val_top-5-accuracy: 0.8116\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 0.9020 - accuracy: 0.7295 - top-5-accuracy: 0.9481 - val_loss: 1.8646 - val_accuracy: 0.5464 - val_top-5-accuracy: 0.8082\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8861 - accuracy: 0.7362 - top-5-accuracy: 0.9494 - val_loss: 1.8927 - val_accuracy: 0.5386 - val_top-5-accuracy: 0.8092\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8812 - accuracy: 0.7368 - top-5-accuracy: 0.9508 - val_loss: 1.9125 - val_accuracy: 0.5398 - val_top-5-accuracy: 0.8054\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 0.8603 - accuracy: 0.7420 - top-5-accuracy: 0.9537 - val_loss: 1.9087 - val_accuracy: 0.5468 - val_top-5-accuracy: 0.8066\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8669 - accuracy: 0.7415 - top-5-accuracy: 0.9511 - val_loss: 1.9136 - val_accuracy: 0.5408 - val_top-5-accuracy: 0.8058\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8682 - accuracy: 0.7394 - top-5-accuracy: 0.9523 - val_loss: 1.9585 - val_accuracy: 0.5300 - val_top-5-accuracy: 0.8044\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8612 - accuracy: 0.7433 - top-5-accuracy: 0.9519 - val_loss: 1.8671 - val_accuracy: 0.5346 - val_top-5-accuracy: 0.8118\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.8474 - accuracy: 0.7464 - top-5-accuracy: 0.9541 - val_loss: 1.9203 - val_accuracy: 0.5448 - val_top-5-accuracy: 0.8116\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 0.8487 - accuracy: 0.7448 - top-5-accuracy: 0.9555 - val_loss: 1.9083 - val_accuracy: 0.5356 - val_top-5-accuracy: 0.8122\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8457 - accuracy: 0.7476 - top-5-accuracy: 0.9542 - val_loss: 1.8966 - val_accuracy: 0.5426 - val_top-5-accuracy: 0.8188\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8356 - accuracy: 0.7502 - top-5-accuracy: 0.9544 - val_loss: 1.9220 - val_accuracy: 0.5360 - val_top-5-accuracy: 0.8080\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.8201 - accuracy: 0.7516 - top-5-accuracy: 0.9570 - val_loss: 1.8944 - val_accuracy: 0.5438 - val_top-5-accuracy: 0.8148\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 0.8240 - accuracy: 0.7508 - top-5-accuracy: 0.9558 - val_loss: 1.9317 - val_accuracy: 0.5432 - val_top-5-accuracy: 0.8098\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.8201 - accuracy: 0.7550 - top-5-accuracy: 0.9578 - val_loss: 1.9288 - val_accuracy: 0.5420 - val_top-5-accuracy: 0.8072\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.8044 - accuracy: 0.7595 - top-5-accuracy: 0.9580 - val_loss: 1.9206 - val_accuracy: 0.5478 - val_top-5-accuracy: 0.8130\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.8121 - accuracy: 0.7570 - top-5-accuracy: 0.9574 - val_loss: 1.9482 - val_accuracy: 0.5426 - val_top-5-accuracy: 0.8088\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8063 - accuracy: 0.7569 - top-5-accuracy: 0.9591 - val_loss: 1.9119 - val_accuracy: 0.5420 - val_top-5-accuracy: 0.8002\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8067 - accuracy: 0.7587 - top-5-accuracy: 0.9567 - val_loss: 1.9367 - val_accuracy: 0.5356 - val_top-5-accuracy: 0.7996\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.8016 - accuracy: 0.7592 - top-5-accuracy: 0.9586 - val_loss: 1.9233 - val_accuracy: 0.5392 - val_top-5-accuracy: 0.8070\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.7952 - accuracy: 0.7615 - top-5-accuracy: 0.9597 - val_loss: 1.9330 - val_accuracy: 0.5424 - val_top-5-accuracy: 0.8108\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.7784 - accuracy: 0.7648 - top-5-accuracy: 0.9620 - val_loss: 1.9188 - val_accuracy: 0.5458 - val_top-5-accuracy: 0.8110\n",
            "Epoch 96/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.7780 - accuracy: 0.7664 - top-5-accuracy: 0.9610 - val_loss: 1.9515 - val_accuracy: 0.5340 - val_top-5-accuracy: 0.8096\n",
            "Epoch 97/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.7747 - accuracy: 0.7672 - top-5-accuracy: 0.9608 - val_loss: 1.9474 - val_accuracy: 0.5470 - val_top-5-accuracy: 0.8094\n",
            "Epoch 98/100\n",
            "176/176 [==============================] - 68s 388ms/step - loss: 0.7820 - accuracy: 0.7643 - top-5-accuracy: 0.9609 - val_loss: 1.9405 - val_accuracy: 0.5516 - val_top-5-accuracy: 0.8112\n",
            "Epoch 99/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.7835 - accuracy: 0.7660 - top-5-accuracy: 0.9600 - val_loss: 1.9026 - val_accuracy: 0.5460 - val_top-5-accuracy: 0.8126\n",
            "Epoch 100/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 0.7720 - accuracy: 0.7671 - top-5-accuracy: 0.9608 - val_loss: 1.8980 - val_accuracy: 0.5532 - val_top-5-accuracy: 0.8162\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 1.8837 - accuracy: 0.5511 - top-5-accuracy: 0.8146\n",
            "Test accuracy: 55.11%\n",
            "Test top 5 accuracy: 81.46%\n"
          ]
        }
      ],
      "source": [
        "ViT = ViT_classifier(x_train = x_train, params = params)\n",
        "history = ViT.train(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueScZ7urkIoe"
      },
      "source": [
        "#### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lfSVA4qv2Hzi"
      },
      "outputs": [],
      "source": [
        "# ViT.model.save(\"drive/MyDrive/CV_Transformer/ViT_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXUUZWKpjYmY"
      },
      "source": [
        "### 4. Train ViT - Superclasses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wBQ4tNVjxRS"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "R5HLL1MGjuzn"
      },
      "outputs": [],
      "source": [
        "params_superclasses = params\n",
        "params_superclasses[\"num_classes\"] = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE765ONgkCg3"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCbYO_WOkM8e",
        "outputId": "164cef53-65e6-470b-f23f-5052d344dfb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 79s 385ms/step - loss: 2.8718 - accuracy: 0.1619 - top-5-accuracy: 0.4909 - val_loss: 2.4081 - val_accuracy: 0.2570 - val_top-5-accuracy: 0.6462\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 2.4297 - accuracy: 0.2502 - top-5-accuracy: 0.6276 - val_loss: 2.1950 - val_accuracy: 0.3230 - val_top-5-accuracy: 0.7020\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 2.2603 - accuracy: 0.3027 - top-5-accuracy: 0.6895 - val_loss: 2.0599 - val_accuracy: 0.3726 - val_top-5-accuracy: 0.7488\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 2.1478 - accuracy: 0.3348 - top-5-accuracy: 0.7243 - val_loss: 1.9332 - val_accuracy: 0.4016 - val_top-5-accuracy: 0.7824\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 2.0647 - accuracy: 0.3639 - top-5-accuracy: 0.7417 - val_loss: 1.8739 - val_accuracy: 0.4240 - val_top-5-accuracy: 0.7898\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.9959 - accuracy: 0.3864 - top-5-accuracy: 0.7636 - val_loss: 1.8079 - val_accuracy: 0.4416 - val_top-5-accuracy: 0.8046\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.9275 - accuracy: 0.4061 - top-5-accuracy: 0.7786 - val_loss: 1.7804 - val_accuracy: 0.4578 - val_top-5-accuracy: 0.8112\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.8658 - accuracy: 0.4217 - top-5-accuracy: 0.7945 - val_loss: 1.7096 - val_accuracy: 0.4672 - val_top-5-accuracy: 0.8276\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.8101 - accuracy: 0.4394 - top-5-accuracy: 0.8048 - val_loss: 1.6723 - val_accuracy: 0.4746 - val_top-5-accuracy: 0.8392\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 65s 369ms/step - loss: 1.7755 - accuracy: 0.4502 - top-5-accuracy: 0.8128 - val_loss: 1.6366 - val_accuracy: 0.5020 - val_top-5-accuracy: 0.8342\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.7128 - accuracy: 0.4724 - top-5-accuracy: 0.8272 - val_loss: 1.5801 - val_accuracy: 0.5136 - val_top-5-accuracy: 0.8472\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 66s 372ms/step - loss: 1.6733 - accuracy: 0.4809 - top-5-accuracy: 0.8351 - val_loss: 1.5655 - val_accuracy: 0.5158 - val_top-5-accuracy: 0.8546\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.6363 - accuracy: 0.4885 - top-5-accuracy: 0.8443 - val_loss: 1.5615 - val_accuracy: 0.5194 - val_top-5-accuracy: 0.8476\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.5892 - accuracy: 0.5066 - top-5-accuracy: 0.8488 - val_loss: 1.5007 - val_accuracy: 0.5338 - val_top-5-accuracy: 0.8610\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.5508 - accuracy: 0.5139 - top-5-accuracy: 0.8588 - val_loss: 1.4543 - val_accuracy: 0.5496 - val_top-5-accuracy: 0.8640\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.5150 - accuracy: 0.5264 - top-5-accuracy: 0.8653 - val_loss: 1.4524 - val_accuracy: 0.5512 - val_top-5-accuracy: 0.8630\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.4854 - accuracy: 0.5337 - top-5-accuracy: 0.8710 - val_loss: 1.4197 - val_accuracy: 0.5588 - val_top-5-accuracy: 0.8730\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.4483 - accuracy: 0.5447 - top-5-accuracy: 0.8753 - val_loss: 1.4158 - val_accuracy: 0.5610 - val_top-5-accuracy: 0.8762\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.4129 - accuracy: 0.5528 - top-5-accuracy: 0.8832 - val_loss: 1.3771 - val_accuracy: 0.5712 - val_top-5-accuracy: 0.8814\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.3823 - accuracy: 0.5661 - top-5-accuracy: 0.8894 - val_loss: 1.4074 - val_accuracy: 0.5670 - val_top-5-accuracy: 0.8768\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.3575 - accuracy: 0.5719 - top-5-accuracy: 0.8922 - val_loss: 1.3963 - val_accuracy: 0.5710 - val_top-5-accuracy: 0.8724\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 65s 369ms/step - loss: 1.3247 - accuracy: 0.5829 - top-5-accuracy: 0.8965 - val_loss: 1.3435 - val_accuracy: 0.5810 - val_top-5-accuracy: 0.8804\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.3100 - accuracy: 0.5879 - top-5-accuracy: 0.8987 - val_loss: 1.3610 - val_accuracy: 0.5808 - val_top-5-accuracy: 0.8778\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.2803 - accuracy: 0.5906 - top-5-accuracy: 0.9039 - val_loss: 1.3404 - val_accuracy: 0.5876 - val_top-5-accuracy: 0.8838\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.2512 - accuracy: 0.6011 - top-5-accuracy: 0.9092 - val_loss: 1.3406 - val_accuracy: 0.5894 - val_top-5-accuracy: 0.8854\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 1.2186 - accuracy: 0.6164 - top-5-accuracy: 0.9127 - val_loss: 1.3109 - val_accuracy: 0.5900 - val_top-5-accuracy: 0.8928\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.2029 - accuracy: 0.6154 - top-5-accuracy: 0.9162 - val_loss: 1.3004 - val_accuracy: 0.5974 - val_top-5-accuracy: 0.8928\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 1.1712 - accuracy: 0.6267 - top-5-accuracy: 0.9213 - val_loss: 1.3091 - val_accuracy: 0.5944 - val_top-5-accuracy: 0.8946\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.1443 - accuracy: 0.6358 - top-5-accuracy: 0.9237 - val_loss: 1.3043 - val_accuracy: 0.5986 - val_top-5-accuracy: 0.8912\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 1.1172 - accuracy: 0.6447 - top-5-accuracy: 0.9280 - val_loss: 1.3200 - val_accuracy: 0.5940 - val_top-5-accuracy: 0.8954\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.0983 - accuracy: 0.6488 - top-5-accuracy: 0.9316 - val_loss: 1.2963 - val_accuracy: 0.6026 - val_top-5-accuracy: 0.8954\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.0584 - accuracy: 0.6591 - top-5-accuracy: 0.9362 - val_loss: 1.2796 - val_accuracy: 0.6090 - val_top-5-accuracy: 0.9008\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 1.0468 - accuracy: 0.6625 - top-5-accuracy: 0.9374 - val_loss: 1.2806 - val_accuracy: 0.6064 - val_top-5-accuracy: 0.8964\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.0256 - accuracy: 0.6722 - top-5-accuracy: 0.9422 - val_loss: 1.2591 - val_accuracy: 0.6156 - val_top-5-accuracy: 0.8990\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.9919 - accuracy: 0.6826 - top-5-accuracy: 0.9435 - val_loss: 1.2511 - val_accuracy: 0.6214 - val_top-5-accuracy: 0.9034\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 65s 369ms/step - loss: 0.9660 - accuracy: 0.6885 - top-5-accuracy: 0.9493 - val_loss: 1.2667 - val_accuracy: 0.6256 - val_top-5-accuracy: 0.9048\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.9438 - accuracy: 0.6946 - top-5-accuracy: 0.9503 - val_loss: 1.2517 - val_accuracy: 0.6266 - val_top-5-accuracy: 0.8996\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 0.9325 - accuracy: 0.6980 - top-5-accuracy: 0.9529 - val_loss: 1.2231 - val_accuracy: 0.6374 - val_top-5-accuracy: 0.9090\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 0.9021 - accuracy: 0.7072 - top-5-accuracy: 0.9550 - val_loss: 1.2284 - val_accuracy: 0.6372 - val_top-5-accuracy: 0.9098\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 64s 363ms/step - loss: 0.8896 - accuracy: 0.7132 - top-5-accuracy: 0.9562 - val_loss: 1.2489 - val_accuracy: 0.6236 - val_top-5-accuracy: 0.9008\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.8518 - accuracy: 0.7262 - top-5-accuracy: 0.9594 - val_loss: 1.2406 - val_accuracy: 0.6258 - val_top-5-accuracy: 0.9034\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8459 - accuracy: 0.7253 - top-5-accuracy: 0.9612 - val_loss: 1.2422 - val_accuracy: 0.6330 - val_top-5-accuracy: 0.9066\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8353 - accuracy: 0.7294 - top-5-accuracy: 0.9626 - val_loss: 1.2442 - val_accuracy: 0.6316 - val_top-5-accuracy: 0.9054\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.8143 - accuracy: 0.7389 - top-5-accuracy: 0.9634 - val_loss: 1.2527 - val_accuracy: 0.6336 - val_top-5-accuracy: 0.9106\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 66s 374ms/step - loss: 0.7955 - accuracy: 0.7419 - top-5-accuracy: 0.9654 - val_loss: 1.2415 - val_accuracy: 0.6428 - val_top-5-accuracy: 0.9042\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.7913 - accuracy: 0.7427 - top-5-accuracy: 0.9677 - val_loss: 1.2575 - val_accuracy: 0.6380 - val_top-5-accuracy: 0.9088\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.7743 - accuracy: 0.7471 - top-5-accuracy: 0.9680 - val_loss: 1.2038 - val_accuracy: 0.6446 - val_top-5-accuracy: 0.9178\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.7491 - accuracy: 0.7552 - top-5-accuracy: 0.9700 - val_loss: 1.2397 - val_accuracy: 0.6332 - val_top-5-accuracy: 0.9106\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.7378 - accuracy: 0.7602 - top-5-accuracy: 0.9719 - val_loss: 1.2256 - val_accuracy: 0.6456 - val_top-5-accuracy: 0.9120\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.7319 - accuracy: 0.7613 - top-5-accuracy: 0.9725 - val_loss: 1.2477 - val_accuracy: 0.6414 - val_top-5-accuracy: 0.9092\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.7194 - accuracy: 0.7660 - top-5-accuracy: 0.9722 - val_loss: 1.2264 - val_accuracy: 0.6400 - val_top-5-accuracy: 0.9086\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 0.7019 - accuracy: 0.7700 - top-5-accuracy: 0.9742 - val_loss: 1.2147 - val_accuracy: 0.6464 - val_top-5-accuracy: 0.9116\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.7059 - accuracy: 0.7700 - top-5-accuracy: 0.9742 - val_loss: 1.2627 - val_accuracy: 0.6396 - val_top-5-accuracy: 0.9076\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 0.6889 - accuracy: 0.7758 - top-5-accuracy: 0.9750 - val_loss: 1.2377 - val_accuracy: 0.6538 - val_top-5-accuracy: 0.9134\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6749 - accuracy: 0.7814 - top-5-accuracy: 0.9770 - val_loss: 1.2474 - val_accuracy: 0.6486 - val_top-5-accuracy: 0.9082\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6640 - accuracy: 0.7831 - top-5-accuracy: 0.9774 - val_loss: 1.2382 - val_accuracy: 0.6432 - val_top-5-accuracy: 0.9090\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6660 - accuracy: 0.7837 - top-5-accuracy: 0.9781 - val_loss: 1.2382 - val_accuracy: 0.6472 - val_top-5-accuracy: 0.9080\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6431 - accuracy: 0.7901 - top-5-accuracy: 0.9793 - val_loss: 1.2450 - val_accuracy: 0.6448 - val_top-5-accuracy: 0.9106\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6343 - accuracy: 0.7934 - top-5-accuracy: 0.9792 - val_loss: 1.2549 - val_accuracy: 0.6514 - val_top-5-accuracy: 0.9118\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6275 - accuracy: 0.7963 - top-5-accuracy: 0.9798 - val_loss: 1.2805 - val_accuracy: 0.6442 - val_top-5-accuracy: 0.9124\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6302 - accuracy: 0.7955 - top-5-accuracy: 0.9803 - val_loss: 1.2998 - val_accuracy: 0.6328 - val_top-5-accuracy: 0.9062\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 65s 367ms/step - loss: 0.6181 - accuracy: 0.7991 - top-5-accuracy: 0.9806 - val_loss: 1.2542 - val_accuracy: 0.6452 - val_top-5-accuracy: 0.9116\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6109 - accuracy: 0.8006 - top-5-accuracy: 0.9815 - val_loss: 1.2632 - val_accuracy: 0.6444 - val_top-5-accuracy: 0.9084\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.6112 - accuracy: 0.8014 - top-5-accuracy: 0.9810 - val_loss: 1.2692 - val_accuracy: 0.6430 - val_top-5-accuracy: 0.9058\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.6017 - accuracy: 0.8018 - top-5-accuracy: 0.9826 - val_loss: 1.2566 - val_accuracy: 0.6496 - val_top-5-accuracy: 0.9114\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.5896 - accuracy: 0.8080 - top-5-accuracy: 0.9840 - val_loss: 1.2725 - val_accuracy: 0.6492 - val_top-5-accuracy: 0.9118\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.5805 - accuracy: 0.8110 - top-5-accuracy: 0.9821 - val_loss: 1.3000 - val_accuracy: 0.6442 - val_top-5-accuracy: 0.9114\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.5786 - accuracy: 0.8096 - top-5-accuracy: 0.9838 - val_loss: 1.2525 - val_accuracy: 0.6522 - val_top-5-accuracy: 0.9130\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.5680 - accuracy: 0.8138 - top-5-accuracy: 0.9838 - val_loss: 1.2977 - val_accuracy: 0.6470 - val_top-5-accuracy: 0.9102\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.5591 - accuracy: 0.8185 - top-5-accuracy: 0.9840 - val_loss: 1.2600 - val_accuracy: 0.6522 - val_top-5-accuracy: 0.9124\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.5598 - accuracy: 0.8154 - top-5-accuracy: 0.9846 - val_loss: 1.3089 - val_accuracy: 0.6494 - val_top-5-accuracy: 0.9132\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.5531 - accuracy: 0.8208 - top-5-accuracy: 0.9847 - val_loss: 1.2803 - val_accuracy: 0.6506 - val_top-5-accuracy: 0.9180\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.5479 - accuracy: 0.8220 - top-5-accuracy: 0.9844 - val_loss: 1.2914 - val_accuracy: 0.6446 - val_top-5-accuracy: 0.9084\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.5431 - accuracy: 0.8231 - top-5-accuracy: 0.9855 - val_loss: 1.2753 - val_accuracy: 0.6450 - val_top-5-accuracy: 0.9078\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.5431 - accuracy: 0.8222 - top-5-accuracy: 0.9839 - val_loss: 1.2943 - val_accuracy: 0.6450 - val_top-5-accuracy: 0.9058\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.5372 - accuracy: 0.8252 - top-5-accuracy: 0.9862 - val_loss: 1.2683 - val_accuracy: 0.6414 - val_top-5-accuracy: 0.9080\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.5348 - accuracy: 0.8228 - top-5-accuracy: 0.9860 - val_loss: 1.2729 - val_accuracy: 0.6506 - val_top-5-accuracy: 0.9128\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.5277 - accuracy: 0.8272 - top-5-accuracy: 0.9859 - val_loss: 1.2756 - val_accuracy: 0.6458 - val_top-5-accuracy: 0.9096\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.5186 - accuracy: 0.8300 - top-5-accuracy: 0.9867 - val_loss: 1.2610 - val_accuracy: 0.6528 - val_top-5-accuracy: 0.9100\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.5235 - accuracy: 0.8302 - top-5-accuracy: 0.9858 - val_loss: 1.2717 - val_accuracy: 0.6512 - val_top-5-accuracy: 0.9048\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.5077 - accuracy: 0.8339 - top-5-accuracy: 0.9876 - val_loss: 1.2668 - val_accuracy: 0.6512 - val_top-5-accuracy: 0.9102\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.5147 - accuracy: 0.8325 - top-5-accuracy: 0.9868 - val_loss: 1.2758 - val_accuracy: 0.6462 - val_top-5-accuracy: 0.9142\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 0.5077 - accuracy: 0.8336 - top-5-accuracy: 0.9875 - val_loss: 1.2339 - val_accuracy: 0.6580 - val_top-5-accuracy: 0.9158\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4988 - accuracy: 0.8376 - top-5-accuracy: 0.9876 - val_loss: 1.2649 - val_accuracy: 0.6514 - val_top-5-accuracy: 0.9100\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.4958 - accuracy: 0.8374 - top-5-accuracy: 0.9875 - val_loss: 1.2712 - val_accuracy: 0.6566 - val_top-5-accuracy: 0.9184\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4996 - accuracy: 0.8383 - top-5-accuracy: 0.9875 - val_loss: 1.3091 - val_accuracy: 0.6536 - val_top-5-accuracy: 0.9130\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4932 - accuracy: 0.8403 - top-5-accuracy: 0.9876 - val_loss: 1.2823 - val_accuracy: 0.6502 - val_top-5-accuracy: 0.9146\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.4956 - accuracy: 0.8370 - top-5-accuracy: 0.9880 - val_loss: 1.2820 - val_accuracy: 0.6546 - val_top-5-accuracy: 0.9160\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4956 - accuracy: 0.8372 - top-5-accuracy: 0.9883 - val_loss: 1.3063 - val_accuracy: 0.6462 - val_top-5-accuracy: 0.9106\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.4898 - accuracy: 0.8382 - top-5-accuracy: 0.9888 - val_loss: 1.3247 - val_accuracy: 0.6448 - val_top-5-accuracy: 0.9152\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.4886 - accuracy: 0.8410 - top-5-accuracy: 0.9880 - val_loss: 1.2927 - val_accuracy: 0.6576 - val_top-5-accuracy: 0.9168\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4820 - accuracy: 0.8421 - top-5-accuracy: 0.9888 - val_loss: 1.2929 - val_accuracy: 0.6504 - val_top-5-accuracy: 0.9160\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4805 - accuracy: 0.8434 - top-5-accuracy: 0.9886 - val_loss: 1.2749 - val_accuracy: 0.6534 - val_top-5-accuracy: 0.9110\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 65s 370ms/step - loss: 0.4750 - accuracy: 0.8430 - top-5-accuracy: 0.9898 - val_loss: 1.2969 - val_accuracy: 0.6588 - val_top-5-accuracy: 0.9144\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4745 - accuracy: 0.8445 - top-5-accuracy: 0.9890 - val_loss: 1.2998 - val_accuracy: 0.6448 - val_top-5-accuracy: 0.9144\n",
            "Epoch 96/100\n",
            "176/176 [==============================] - 64s 365ms/step - loss: 0.4738 - accuracy: 0.8435 - top-5-accuracy: 0.9892 - val_loss: 1.2969 - val_accuracy: 0.6566 - val_top-5-accuracy: 0.9156\n",
            "Epoch 97/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4704 - accuracy: 0.8476 - top-5-accuracy: 0.9897 - val_loss: 1.2956 - val_accuracy: 0.6458 - val_top-5-accuracy: 0.9068\n",
            "Epoch 98/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4540 - accuracy: 0.8516 - top-5-accuracy: 0.9908 - val_loss: 1.2589 - val_accuracy: 0.6500 - val_top-5-accuracy: 0.9078\n",
            "Epoch 99/100\n",
            "176/176 [==============================] - 64s 366ms/step - loss: 0.4600 - accuracy: 0.8484 - top-5-accuracy: 0.9893 - val_loss: 1.2978 - val_accuracy: 0.6464 - val_top-5-accuracy: 0.9150\n",
            "Epoch 100/100\n",
            "176/176 [==============================] - 64s 364ms/step - loss: 0.4655 - accuracy: 0.8462 - top-5-accuracy: 0.9894 - val_loss: 1.2796 - val_accuracy: 0.6550 - val_top-5-accuracy: 0.9122\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.3019 - accuracy: 0.6528 - top-5-accuracy: 0.9149\n",
            "Test accuracy: 65.28%\n",
            "Test top 5 accuracy: 91.49%\n"
          ]
        }
      ],
      "source": [
        "ViT = ViT_classifier(x_train = x_train, params = params_superclasses)\n",
        "history = ViT.train(x_train=x_train, x_test=x_test, y_train=ys_train, y_test=ys_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo84CLVUkEDa"
      },
      "source": [
        "#### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odBfntPAkaF2"
      },
      "outputs": [],
      "source": [
        "# ViT.model.save(\"drive/MyDrive/CV_Transformer/ViT_model_superclasses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWFRjY5Njp9z"
      },
      "source": [
        "### 5. Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBkGSvmf2Hze"
      },
      "source": [
        "#### Show patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjfkxWPAg93-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "example = np.random.choice(range(x_test.shape[0]))\n",
        "image = x_test[example]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "print(\"Class:\")\n",
        "print(f\"True: {fine_label_names[y_test[example,0]]}\")\n",
        "print(f\"Predicted: {fine_label_names[np.argmax(model(image.reshape((1,32,32,3))))]}\")\n",
        "print(\"\\n\")\n",
        "print(\"Superclass:\")\n",
        "print(f\"True: {coarse_label_names[ys_test[example,0]]}\")\n",
        "print(f\"Predicted: {coarse_label_names[np.argmax(model_superclasses(image.reshape((1,32,32,3))))]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNuBRCdDg93_"
      },
      "source": [
        "#### Show results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASzeLe42aHNh"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"drive/MyDrive/CV_Transformer/ViT_model\")\n",
        "model_superclasses = tf.keras.models.load_model(\"drive/MyDrive/CV_Transformer/ViT_model_superclasses\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcLnAHDzCpAO"
      },
      "outputs": [],
      "source": [
        "file = \"drive/MyDrive/CV_Transformer/cifar-100-python/meta\"\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "dict = unpickle(file)\n",
        "fine_label_names = dict[b\"fine_label_names\"]\n",
        "coarse_label_names = dict[b\"coarse_label_names\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVqoKW_nbBrh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "example = np.random.choice(range(x_test.shape[0]))\n",
        "image = x_test[example]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "print(\"Class:\")\n",
        "print(f\"True: {fine_label_names[y_test[example,0]]}\")\n",
        "print(f\"Predicted: {fine_label_names[np.argmax(model(image.reshape((1,32,32,3))))]}\")\n",
        "print(\"\\n\")\n",
        "print(\"Superclass:\")\n",
        "print(f\"True: {coarse_label_names[ys_test[example,0]]}\")\n",
        "print(f\"Predicted: {coarse_label_names[np.argmax(model_superclasses(image.reshape((1,32,32,3))))]}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "aHtEab4S2HzU",
        "04POw8yy2Hzc",
        "vYaWf6-32Hzd",
        "qX2zVYngjoYc",
        "ueScZ7urkIoe",
        "0wBQ4tNVjxRS",
        "DE765ONgkCg3",
        "Jo84CLVUkEDa",
        "sWFRjY5Njp9z",
        "wBkGSvmf2Hze"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}