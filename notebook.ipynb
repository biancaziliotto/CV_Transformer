{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJGrwq-I9Uxy"
      },
      "source": [
        "### 0. Use Google Colab\n",
        "(Senn√≤ va stralento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H7-7-lD2Iuj",
        "outputId": "22c5a801-f57b-4d42-dcc7-b5c702e9a9ea"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HolaiWOX3jPL",
        "outputId": "4ab57946-128c-4db1-a45b-4d8e0d78caab"
      },
      "outputs": [],
      "source": [
        "# !pip install -r drive/MyDrive/CV_Transformer/requirements.txt\n",
        "# !pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWmdv-xQ3DGB",
        "outputId": "ea119958-78f8-49e4-c9ab-271157eb4ac7"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# notebook_path = os.getcwd()\n",
        "# print(notebook_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHtEab4S2HzU"
      },
      "source": [
        "### 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-sczZSR2HzZ",
        "outputId": "07839d35-a72b-4e0d-ab6d-4a4f547c65d9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.ViT import ViT_classifier\n",
        "from src.BuildingBlocks import Patches\n",
        "# from drive.MyDrive.CV_Transformer.src.ViT import ViT_classifier\n",
        "# from drive.MyDrive.CV_Transformer.src.BuildingBlocks import Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8eQLm0ZJ2Hzb"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04POw8yy2Hzc"
      },
      "source": [
        "### 2. Data loading and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fAq7nxa2Hzc",
        "outputId": "adf890a9-d8f5-48f3-d8c2-d92919a3b06c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYaWf6-32Hzd"
      },
      "source": [
        "### 3. Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tE-hWZew2Hze"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"learning_rate\" : 0.001,\n",
        "    \"weight_decay\" : 0.0001,\n",
        "    \"batch_size\" : 256,\n",
        "    \"num_epochs\" : 100,\n",
        "    \"input_shape\" : (32, 32, 3),\n",
        "    \"num_classes\" : 100,\n",
        "    \"image_size\" : 72,  # We'll resize input images to this size\n",
        "    \"patch_size\" : 6,  # Size of the patches to be extract from the input images\n",
        "    \"projection_dim\" : 64,\n",
        "    \"num_heads\" : 4,\n",
        "    \"transformer_units\" : [128, 64], # Size of the transformer layers\n",
        "    \"transformer_layers\" : 8,\n",
        "    \"mlp_head_units\" : [2048, 1024]  # Size of the dense layers of the final classifier\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBkGSvmf2Hze"
      },
      "source": [
        "### 4. Show patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "-c9nHa0U2Hzg",
        "outputId": "fb8cfd41-22aa-4620-df6e-3214267ed48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(params[\"image_size\"], params[\"image_size\"])\n",
        ")\n",
        "\n",
        "extract_patches = Patches(params[\"patch_size\"])\n",
        "patches = extract_patches(resized_image)\n",
        "print(f\"Image size: {params['image_size']} X {params['image_size']}\")\n",
        "print(f\"Patch size: {params['patch_size']} X {params['patch_size']}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (params[\"patch_size\"], params[\"patch_size\"], 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tYHENVS2Hzh"
      },
      "source": [
        "### 5. Train ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaC4bSuu2Hzi",
        "outputId": "d62ca9fa-f54d-4a51-b974-d270472e32a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 81s 377ms/step - loss: 4.4819 - accuracy: 0.0461 - top-5-accuracy: 0.1588 - val_loss: 3.9627 - val_accuracy: 0.1036 - val_top-5-accuracy: 0.3018\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 67s 381ms/step - loss: 3.9432 - accuracy: 0.0972 - top-5-accuracy: 0.2905 - val_loss: 3.5497 - val_accuracy: 0.1678 - val_top-5-accuracy: 0.4188\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 67s 379ms/step - loss: 3.6917 - accuracy: 0.1326 - top-5-accuracy: 0.3629 - val_loss: 3.3412 - val_accuracy: 0.1920 - val_top-5-accuracy: 0.4706\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 66s 376ms/step - loss: 3.5254 - accuracy: 0.1564 - top-5-accuracy: 0.4130 - val_loss: 3.2536 - val_accuracy: 0.2128 - val_top-5-accuracy: 0.5008\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 66s 377ms/step - loss: 3.4013 - accuracy: 0.1808 - top-5-accuracy: 0.4508 - val_loss: 3.0901 - val_accuracy: 0.2442 - val_top-5-accuracy: 0.5334\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 67s 378ms/step - loss: 3.2852 - accuracy: 0.1990 - top-5-accuracy: 0.4835 - val_loss: 3.0029 - val_accuracy: 0.2666 - val_top-5-accuracy: 0.5546\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 66s 377ms/step - loss: 3.1781 - accuracy: 0.2222 - top-5-accuracy: 0.5115 - val_loss: 2.8569 - val_accuracy: 0.2866 - val_top-5-accuracy: 0.5940\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 67s 379ms/step - loss: 3.0641 - accuracy: 0.2443 - top-5-accuracy: 0.5411 - val_loss: 2.7865 - val_accuracy: 0.3014 - val_top-5-accuracy: 0.6022\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 67s 380ms/step - loss: 2.9634 - accuracy: 0.2628 - top-5-accuracy: 0.5636 - val_loss: 2.7331 - val_accuracy: 0.3094 - val_top-5-accuracy: 0.6190\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 2.8819 - accuracy: 0.2816 - top-5-accuracy: 0.5850 - val_loss: 2.6209 - val_accuracy: 0.3418 - val_top-5-accuracy: 0.6440\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 2.8098 - accuracy: 0.2941 - top-5-accuracy: 0.6020 - val_loss: 2.5967 - val_accuracy: 0.3454 - val_top-5-accuracy: 0.6528\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 66s 377ms/step - loss: 2.7450 - accuracy: 0.3087 - top-5-accuracy: 0.6155 - val_loss: 2.5462 - val_accuracy: 0.3562 - val_top-5-accuracy: 0.6660\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 66s 376ms/step - loss: 2.6745 - accuracy: 0.3233 - top-5-accuracy: 0.6309 - val_loss: 2.4790 - val_accuracy: 0.3692 - val_top-5-accuracy: 0.6738\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 66s 376ms/step - loss: 2.6126 - accuracy: 0.3346 - top-5-accuracy: 0.6484 - val_loss: 2.4673 - val_accuracy: 0.3706 - val_top-5-accuracy: 0.6690\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 67s 379ms/step - loss: 2.5531 - accuracy: 0.3459 - top-5-accuracy: 0.6590 - val_loss: 2.3963 - val_accuracy: 0.3866 - val_top-5-accuracy: 0.6884\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 67s 380ms/step - loss: 2.4775 - accuracy: 0.3630 - top-5-accuracy: 0.6752 - val_loss: 2.3357 - val_accuracy: 0.3998 - val_top-5-accuracy: 0.6992\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 66s 376ms/step - loss: 2.4095 - accuracy: 0.3747 - top-5-accuracy: 0.6907 - val_loss: 2.2785 - val_accuracy: 0.4124 - val_top-5-accuracy: 0.7064\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 2.3551 - accuracy: 0.3892 - top-5-accuracy: 0.7009 - val_loss: 2.2385 - val_accuracy: 0.4220 - val_top-5-accuracy: 0.7156\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 2.2915 - accuracy: 0.4008 - top-5-accuracy: 0.7146 - val_loss: 2.2233 - val_accuracy: 0.4234 - val_top-5-accuracy: 0.7258\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 66s 377ms/step - loss: 2.2438 - accuracy: 0.4114 - top-5-accuracy: 0.7271 - val_loss: 2.2097 - val_accuracy: 0.4252 - val_top-5-accuracy: 0.7240\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 2.1866 - accuracy: 0.4222 - top-5-accuracy: 0.7385 - val_loss: 2.1551 - val_accuracy: 0.4446 - val_top-5-accuracy: 0.7372\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 2.1302 - accuracy: 0.4355 - top-5-accuracy: 0.7470 - val_loss: 2.1583 - val_accuracy: 0.4410 - val_top-5-accuracy: 0.7394\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 66s 376ms/step - loss: 2.0875 - accuracy: 0.4453 - top-5-accuracy: 0.7559 - val_loss: 2.1148 - val_accuracy: 0.4486 - val_top-5-accuracy: 0.7460\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 2.0390 - accuracy: 0.4536 - top-5-accuracy: 0.7672 - val_loss: 2.0944 - val_accuracy: 0.4480 - val_top-5-accuracy: 0.7508\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 1.9886 - accuracy: 0.4637 - top-5-accuracy: 0.7767 - val_loss: 2.0501 - val_accuracy: 0.4684 - val_top-5-accuracy: 0.7586\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 66s 372ms/step - loss: 1.9466 - accuracy: 0.4740 - top-5-accuracy: 0.7842 - val_loss: 2.0436 - val_accuracy: 0.4672 - val_top-5-accuracy: 0.7616\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 67s 379ms/step - loss: 1.9141 - accuracy: 0.4844 - top-5-accuracy: 0.7902 - val_loss: 2.0146 - val_accuracy: 0.4752 - val_top-5-accuracy: 0.7644\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.8649 - accuracy: 0.4926 - top-5-accuracy: 0.8010 - val_loss: 2.0347 - val_accuracy: 0.4674 - val_top-5-accuracy: 0.7706\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 1.8325 - accuracy: 0.5019 - top-5-accuracy: 0.8053 - val_loss: 2.0104 - val_accuracy: 0.4822 - val_top-5-accuracy: 0.7630\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.7917 - accuracy: 0.5118 - top-5-accuracy: 0.8139 - val_loss: 2.0006 - val_accuracy: 0.4758 - val_top-5-accuracy: 0.7708\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.7499 - accuracy: 0.5178 - top-5-accuracy: 0.8207 - val_loss: 1.9649 - val_accuracy: 0.4796 - val_top-5-accuracy: 0.7812\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.7275 - accuracy: 0.5242 - top-5-accuracy: 0.8238 - val_loss: 1.9739 - val_accuracy: 0.4792 - val_top-5-accuracy: 0.7790\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 67s 382ms/step - loss: 1.6796 - accuracy: 0.5345 - top-5-accuracy: 0.8341 - val_loss: 1.9225 - val_accuracy: 0.4940 - val_top-5-accuracy: 0.7870\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.6498 - accuracy: 0.5397 - top-5-accuracy: 0.8388 - val_loss: 1.9493 - val_accuracy: 0.4886 - val_top-5-accuracy: 0.7826\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.6201 - accuracy: 0.5474 - top-5-accuracy: 0.8443 - val_loss: 1.9567 - val_accuracy: 0.4858 - val_top-5-accuracy: 0.7822\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.5820 - accuracy: 0.5571 - top-5-accuracy: 0.8501 - val_loss: 1.9366 - val_accuracy: 0.4934 - val_top-5-accuracy: 0.7838\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 66s 376ms/step - loss: 1.5528 - accuracy: 0.5653 - top-5-accuracy: 0.8546 - val_loss: 1.9259 - val_accuracy: 0.4974 - val_top-5-accuracy: 0.7886\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.5165 - accuracy: 0.5751 - top-5-accuracy: 0.8603 - val_loss: 1.9104 - val_accuracy: 0.4956 - val_top-5-accuracy: 0.7900\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 67s 380ms/step - loss: 1.4922 - accuracy: 0.5797 - top-5-accuracy: 0.8649 - val_loss: 1.8862 - val_accuracy: 0.5078 - val_top-5-accuracy: 0.7956\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.4688 - accuracy: 0.5840 - top-5-accuracy: 0.8696 - val_loss: 1.9134 - val_accuracy: 0.5040 - val_top-5-accuracy: 0.7920\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.4403 - accuracy: 0.5918 - top-5-accuracy: 0.8741 - val_loss: 1.8864 - val_accuracy: 0.5028 - val_top-5-accuracy: 0.8004\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.4162 - accuracy: 0.5978 - top-5-accuracy: 0.8762 - val_loss: 1.8908 - val_accuracy: 0.5066 - val_top-5-accuracy: 0.7956\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.3990 - accuracy: 0.6043 - top-5-accuracy: 0.8802 - val_loss: 1.8974 - val_accuracy: 0.5052 - val_top-5-accuracy: 0.7942\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 67s 383ms/step - loss: 1.3728 - accuracy: 0.6073 - top-5-accuracy: 0.8861 - val_loss: 1.8901 - val_accuracy: 0.5110 - val_top-5-accuracy: 0.7988\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 67s 379ms/step - loss: 1.3477 - accuracy: 0.6130 - top-5-accuracy: 0.8894 - val_loss: 1.8884 - val_accuracy: 0.5166 - val_top-5-accuracy: 0.8002\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 66s 377ms/step - loss: 1.3280 - accuracy: 0.6175 - top-5-accuracy: 0.8919 - val_loss: 1.8765 - val_accuracy: 0.5220 - val_top-5-accuracy: 0.7986\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.3186 - accuracy: 0.6221 - top-5-accuracy: 0.8933 - val_loss: 1.9069 - val_accuracy: 0.5152 - val_top-5-accuracy: 0.7854\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.2842 - accuracy: 0.6287 - top-5-accuracy: 0.8962 - val_loss: 1.9064 - val_accuracy: 0.5114 - val_top-5-accuracy: 0.7972\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.2641 - accuracy: 0.6341 - top-5-accuracy: 0.8994 - val_loss: 1.8834 - val_accuracy: 0.5174 - val_top-5-accuracy: 0.8004\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.2449 - accuracy: 0.6384 - top-5-accuracy: 0.9055 - val_loss: 1.8893 - val_accuracy: 0.5208 - val_top-5-accuracy: 0.8002\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.2283 - accuracy: 0.6462 - top-5-accuracy: 0.9055 - val_loss: 1.9005 - val_accuracy: 0.5176 - val_top-5-accuracy: 0.7976\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 66s 377ms/step - loss: 1.2093 - accuracy: 0.6495 - top-5-accuracy: 0.9092 - val_loss: 1.8841 - val_accuracy: 0.5232 - val_top-5-accuracy: 0.8040\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 66s 376ms/step - loss: 1.2038 - accuracy: 0.6510 - top-5-accuracy: 0.9095 - val_loss: 1.8809 - val_accuracy: 0.5264 - val_top-5-accuracy: 0.8040\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 66s 377ms/step - loss: 1.1804 - accuracy: 0.6566 - top-5-accuracy: 0.9126 - val_loss: 1.8510 - val_accuracy: 0.5278 - val_top-5-accuracy: 0.8086\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.1488 - accuracy: 0.6650 - top-5-accuracy: 0.9155 - val_loss: 1.8746 - val_accuracy: 0.5204 - val_top-5-accuracy: 0.8072\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.1487 - accuracy: 0.6658 - top-5-accuracy: 0.9169 - val_loss: 1.9114 - val_accuracy: 0.5132 - val_top-5-accuracy: 0.8050\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.1330 - accuracy: 0.6657 - top-5-accuracy: 0.9200 - val_loss: 1.8765 - val_accuracy: 0.5262 - val_top-5-accuracy: 0.8094\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 1.1051 - accuracy: 0.6767 - top-5-accuracy: 0.9233 - val_loss: 1.8851 - val_accuracy: 0.5232 - val_top-5-accuracy: 0.8044\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.0916 - accuracy: 0.6798 - top-5-accuracy: 0.9256 - val_loss: 1.8818 - val_accuracy: 0.5252 - val_top-5-accuracy: 0.8080\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 67s 379ms/step - loss: 1.0919 - accuracy: 0.6793 - top-5-accuracy: 0.9257 - val_loss: 1.8782 - val_accuracy: 0.5286 - val_top-5-accuracy: 0.8094\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 67s 380ms/step - loss: 1.0870 - accuracy: 0.6812 - top-5-accuracy: 0.9257 - val_loss: 1.8735 - val_accuracy: 0.5318 - val_top-5-accuracy: 0.8064\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 1.0574 - accuracy: 0.6887 - top-5-accuracy: 0.9290 - val_loss: 1.8839 - val_accuracy: 0.5288 - val_top-5-accuracy: 0.8080\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.0642 - accuracy: 0.6881 - top-5-accuracy: 0.9293 - val_loss: 1.8830 - val_accuracy: 0.5260 - val_top-5-accuracy: 0.8058\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.0459 - accuracy: 0.6899 - top-5-accuracy: 0.9314 - val_loss: 1.8581 - val_accuracy: 0.5274 - val_top-5-accuracy: 0.8126\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.0302 - accuracy: 0.6954 - top-5-accuracy: 0.9330 - val_loss: 1.9118 - val_accuracy: 0.5250 - val_top-5-accuracy: 0.8028\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.0168 - accuracy: 0.6986 - top-5-accuracy: 0.9350 - val_loss: 1.8824 - val_accuracy: 0.5294 - val_top-5-accuracy: 0.8028\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 1.0074 - accuracy: 0.7028 - top-5-accuracy: 0.9355 - val_loss: 1.8754 - val_accuracy: 0.5308 - val_top-5-accuracy: 0.8084\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.9947 - accuracy: 0.7060 - top-5-accuracy: 0.9374 - val_loss: 1.9090 - val_accuracy: 0.5284 - val_top-5-accuracy: 0.8118\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 66s 378ms/step - loss: 0.9874 - accuracy: 0.7091 - top-5-accuracy: 0.9383 - val_loss: 1.8831 - val_accuracy: 0.5362 - val_top-5-accuracy: 0.8140\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.9739 - accuracy: 0.7116 - top-5-accuracy: 0.9414 - val_loss: 1.8900 - val_accuracy: 0.5316 - val_top-5-accuracy: 0.8106\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 67s 381ms/step - loss: 0.9755 - accuracy: 0.7102 - top-5-accuracy: 0.9401 - val_loss: 1.8554 - val_accuracy: 0.5382 - val_top-5-accuracy: 0.8122\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 67s 380ms/step - loss: 0.9586 - accuracy: 0.7165 - top-5-accuracy: 0.9404 - val_loss: 1.8871 - val_accuracy: 0.5388 - val_top-5-accuracy: 0.8134\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.9552 - accuracy: 0.7146 - top-5-accuracy: 0.9412 - val_loss: 1.8851 - val_accuracy: 0.5368 - val_top-5-accuracy: 0.8090\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.9514 - accuracy: 0.7163 - top-5-accuracy: 0.9428 - val_loss: 1.8976 - val_accuracy: 0.5304 - val_top-5-accuracy: 0.8060\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.9288 - accuracy: 0.7241 - top-5-accuracy: 0.9442 - val_loss: 1.8934 - val_accuracy: 0.5352 - val_top-5-accuracy: 0.8128\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 66s 372ms/step - loss: 0.9148 - accuracy: 0.7287 - top-5-accuracy: 0.9460 - val_loss: 1.8974 - val_accuracy: 0.5356 - val_top-5-accuracy: 0.8164\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.9075 - accuracy: 0.7306 - top-5-accuracy: 0.9481 - val_loss: 1.8935 - val_accuracy: 0.5224 - val_top-5-accuracy: 0.8066\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.9104 - accuracy: 0.7306 - top-5-accuracy: 0.9473 - val_loss: 1.9031 - val_accuracy: 0.5328 - val_top-5-accuracy: 0.8072\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.9037 - accuracy: 0.7286 - top-5-accuracy: 0.9487 - val_loss: 1.9014 - val_accuracy: 0.5294 - val_top-5-accuracy: 0.8088\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.9022 - accuracy: 0.7306 - top-5-accuracy: 0.9487 - val_loss: 1.8989 - val_accuracy: 0.5362 - val_top-5-accuracy: 0.8130\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.8824 - accuracy: 0.7368 - top-5-accuracy: 0.9510 - val_loss: 1.8904 - val_accuracy: 0.5360 - val_top-5-accuracy: 0.8122\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 67s 379ms/step - loss: 0.8803 - accuracy: 0.7361 - top-5-accuracy: 0.9504 - val_loss: 1.8867 - val_accuracy: 0.5446 - val_top-5-accuracy: 0.8144\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.8752 - accuracy: 0.7394 - top-5-accuracy: 0.9503 - val_loss: 1.9013 - val_accuracy: 0.5326 - val_top-5-accuracy: 0.8176\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.8713 - accuracy: 0.7373 - top-5-accuracy: 0.9519 - val_loss: 1.9164 - val_accuracy: 0.5346 - val_top-5-accuracy: 0.8158\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.8669 - accuracy: 0.7410 - top-5-accuracy: 0.9518 - val_loss: 1.8972 - val_accuracy: 0.5346 - val_top-5-accuracy: 0.8122\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.8623 - accuracy: 0.7405 - top-5-accuracy: 0.9533 - val_loss: 1.9244 - val_accuracy: 0.5340 - val_top-5-accuracy: 0.8100\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.8570 - accuracy: 0.7432 - top-5-accuracy: 0.9530 - val_loss: 1.8922 - val_accuracy: 0.5426 - val_top-5-accuracy: 0.8124\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.8412 - accuracy: 0.7493 - top-5-accuracy: 0.9544 - val_loss: 1.8834 - val_accuracy: 0.5432 - val_top-5-accuracy: 0.8146\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 66s 374ms/step - loss: 0.8387 - accuracy: 0.7484 - top-5-accuracy: 0.9556 - val_loss: 1.9161 - val_accuracy: 0.5360 - val_top-5-accuracy: 0.8168\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.8399 - accuracy: 0.7487 - top-5-accuracy: 0.9546 - val_loss: 1.9338 - val_accuracy: 0.5370 - val_top-5-accuracy: 0.8130\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.8301 - accuracy: 0.7503 - top-5-accuracy: 0.9564 - val_loss: 1.9163 - val_accuracy: 0.5382 - val_top-5-accuracy: 0.8162\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 65s 372ms/step - loss: 0.8283 - accuracy: 0.7527 - top-5-accuracy: 0.9549 - val_loss: 1.9128 - val_accuracy: 0.5418 - val_top-5-accuracy: 0.8132\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 0.8236 - accuracy: 0.7535 - top-5-accuracy: 0.9584 - val_loss: 1.9061 - val_accuracy: 0.5354 - val_top-5-accuracy: 0.8098\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.8255 - accuracy: 0.7532 - top-5-accuracy: 0.9549 - val_loss: 1.9169 - val_accuracy: 0.5392 - val_top-5-accuracy: 0.8134\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.8068 - accuracy: 0.7586 - top-5-accuracy: 0.9584 - val_loss: 1.9166 - val_accuracy: 0.5378 - val_top-5-accuracy: 0.8026\n",
            "Epoch 96/100\n",
            "176/176 [==============================] - 66s 372ms/step - loss: 0.8164 - accuracy: 0.7553 - top-5-accuracy: 0.9568 - val_loss: 1.8964 - val_accuracy: 0.5410 - val_top-5-accuracy: 0.8118\n",
            "Epoch 97/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.7999 - accuracy: 0.7602 - top-5-accuracy: 0.9568 - val_loss: 1.9475 - val_accuracy: 0.5346 - val_top-5-accuracy: 0.8044\n",
            "Epoch 98/100\n",
            "176/176 [==============================] - 65s 371ms/step - loss: 0.8079 - accuracy: 0.7581 - top-5-accuracy: 0.9592 - val_loss: 1.9625 - val_accuracy: 0.5414 - val_top-5-accuracy: 0.8136\n",
            "Epoch 99/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.7944 - accuracy: 0.7611 - top-5-accuracy: 0.9588 - val_loss: 1.9284 - val_accuracy: 0.5408 - val_top-5-accuracy: 0.8102\n",
            "Epoch 100/100\n",
            "176/176 [==============================] - 66s 373ms/step - loss: 0.7994 - accuracy: 0.7616 - top-5-accuracy: 0.9588 - val_loss: 1.9388 - val_accuracy: 0.5342 - val_top-5-accuracy: 0.8074\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 1.8623 - accuracy: 0.5491 - top-5-accuracy: 0.8141\n",
            "Test accuracy: 54.91%\n",
            "Test top 5 accuracy: 81.41%\n"
          ]
        }
      ],
      "source": [
        "ViT = ViT_classifier(x_train = x_train, params = params)\n",
        "history = ViT.train(x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N48qXYkRjIa1"
      },
      "source": [
        "### 6. Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfSVA4qv2Hzi",
        "outputId": "48e7b0e2-6c5a-445a-9e3f-819d1fb13d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " data_augmentation (Sequent  (None, 72, 72, 3)            7         ['input_1[0][0]']             \n",
            " ial)                                                                                             \n",
            "                                                                                                  \n",
            " patches_1 (Patches)         (None, None, 108)            0         ['data_augmentation[0][0]']   \n",
            "                                                                                                  \n",
            " patch_encoder (PatchEncode  (None, 144, 64)              16192     ['patches_1[0][0]']           \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 144, 64)              128       ['patch_encoder[0][0]']       \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 144, 64)              66368     ['layer_normalization[0][0]', \n",
            " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 144, 64)              0         ['multi_head_attention[0][0]',\n",
            "                                                                     'patch_encoder[0][0]']       \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 144, 64)              128       ['add[0][0]']                 \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 144, 128)             8320      ['layer_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 144, 128)             0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 144, 64)              8256      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 144, 64)              0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 144, 64)              0         ['dropout_1[0][0]',           \n",
            "                                                                     'add[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 144, 64)              128       ['add_1[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 144, 64)              66368     ['layer_normalization_2[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 144, 64)              0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_1[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 144, 64)              128       ['add_2[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 144, 128)             8320      ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 144, 128)             0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 144, 64)              8256      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 144, 64)              0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 144, 64)              0         ['dropout_3[0][0]',           \n",
            "                                                                     'add_2[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 144, 64)              128       ['add_3[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 144, 64)              66368     ['layer_normalization_4[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 144, 64)              0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_3[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 144, 64)              128       ['add_4[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 144, 128)             8320      ['layer_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 144, 128)             0         ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 144, 64)              8256      ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 144, 64)              0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 144, 64)              0         ['dropout_5[0][0]',           \n",
            "                                                                     'add_4[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 144, 64)              128       ['add_5[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 144, 64)              66368     ['layer_normalization_6[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 144, 64)              0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_5[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, 144, 64)              128       ['add_6[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 144, 128)             8320      ['layer_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 144, 128)             0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 144, 64)              8256      ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 144, 64)              0         ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 144, 64)              0         ['dropout_7[0][0]',           \n",
            "                                                                     'add_6[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_8 (Lay  (None, 144, 64)              128       ['add_7[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, 144, 64)              66368     ['layer_normalization_8[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 144, 64)              0         ['multi_head_attention_4[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_9 (Lay  (None, 144, 64)              128       ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 144, 128)             8320      ['layer_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 144, 128)             0         ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 144, 64)              8256      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 144, 64)              0         ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 144, 64)              0         ['dropout_9[0][0]',           \n",
            "                                                                     'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_10 (La  (None, 144, 64)              128       ['add_9[0][0]']               \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (Mu  (None, 144, 64)              66368     ['layer_normalization_10[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 144, 64)              0         ['multi_head_attention_5[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_9[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_11 (La  (None, 144, 64)              128       ['add_10[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 144, 128)             8320      ['layer_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 144, 128)             0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 144, 64)              8256      ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 144, 64)              0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 144, 64)              0         ['dropout_11[0][0]',          \n",
            "                                                                     'add_10[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_12 (La  (None, 144, 64)              128       ['add_11[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (Mu  (None, 144, 64)              66368     ['layer_normalization_12[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 144, 64)              0         ['multi_head_attention_6[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_11[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_13 (La  (None, 144, 64)              128       ['add_12[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 144, 128)             8320      ['layer_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 144, 128)             0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 144, 64)              8256      ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 144, 64)              0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 144, 64)              0         ['dropout_13[0][0]',          \n",
            "                                                                     'add_12[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_14 (La  (None, 144, 64)              128       ['add_13[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (Mu  (None, 144, 64)              66368     ['layer_normalization_14[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 144, 64)              0         ['multi_head_attention_7[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_13[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_15 (La  (None, 144, 64)              128       ['add_14[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 144, 128)             8320      ['layer_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 144, 128)             0         ['dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 144, 64)              8256      ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 144, 64)              0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 144, 64)              0         ['dropout_15[0][0]',          \n",
            "                                                                     'add_14[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_16 (La  (None, 144, 64)              128       ['add_15[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 9216)                 0         ['layer_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 9216)                 0         ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 2048)                 1887641   ['dropout_16[0][0]']          \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 2048)                 0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 1024)                 2098176   ['dropout_17[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)        (None, 1024)                 0         ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 100)                  102500    ['dropout_18[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21759019 (83.00 MB)\n",
            "Trainable params: 21759012 (83.00 MB)\n",
            "Non-trainable params: 7 (32.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "ViT.model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RJGrwq-I9Uxy",
        "aHtEab4S2HzU",
        "04POw8yy2Hzc",
        "vYaWf6-32Hzd",
        "wBkGSvmf2Hze",
        "N48qXYkRjIa1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
